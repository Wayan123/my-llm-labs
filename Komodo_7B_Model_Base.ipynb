{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Card for Komodo-7B-Base\n",
        "Komodo-7B-Base is a large language model that is developed through incremental pretraining and vocabulary expansion on top of Llama-2-7B-Base. This model can handle Indonesian, English and 11 regional languages of Indonesia.\n",
        "\n",
        "Disclaimer : This is not an instruction-tuned model, further fine-tuning is needed for downstream tasks. For example, people usually utilize the Alpaca dataset for further fine-tuning on top of Llama-2-7B-Base model. Hence, there is no prompt template for this model.\n",
        "\n",
        "link: https://huggingface.co/Yellow-AI-NLP/komodo-7b-base\n"
      ],
      "metadata": {
        "id": "L9RiVxGmIV9Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Description\n",
        "More details can be found in our paper: https://arxiv.org/abs/2403.09362\n",
        "\n",
        "Developed by: Yellow.ai\n",
        "\n",
        "Model type: Decoder\n",
        "\n",
        "Languages: English, Indonesian, Acehnese, Balinese, Banjarese, Buginese, Madurese, Minangkabau, Javanese, Dayak Ngaju, Sundanese, Toba Batak, Lampungnese\n",
        "License: llama2"
      ],
      "metadata": {
        "id": "FMvaG5pRWgxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-dotenv\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "ltrT06wbIc2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import huggingface_hub\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "1k2dcoXDLQ0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usage Example\n",
        "Since this is a gated model, you need to logged in to your HF account before using the model. Below is one way to do this. You can get the HF Token from your profile (Profile -> Settings -> Access Tokens)"
      ],
      "metadata": {
        "id": "UzGfNvZaWql_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_hub.login(\"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\") # Set role ke write"
      ],
      "metadata": {
        "id": "pNYEC9KYL9WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Yellow-AI-NLP/komodo-7b-base\",trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Yellow-AI-NLP/komodo-7b-base\",trust_remote_code=True)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "rBWfieV-LXpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_prompt = \"Candi borobudur adalah\"\n",
        "\n",
        "tokens = tokenizer(full_prompt, return_tensors=\"pt\").to(device)\n",
        "output = model.generate(tokens[\"input_ids\"], eos_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "# Candi borobudur adalah candi yang terletak di Magelang, Jawa Tengah.\n"
      ],
      "metadata": {
        "id": "9SzbV6aFV1al"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}